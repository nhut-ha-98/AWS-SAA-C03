# AWS Data Transfer Services Guide ğŸšš

*Comprehensive guide to AWS data transfer solutions, from edge computing to massive migrations*

## ğŸ¯ Overview

AWS provides multiple data transfer services to handle different scenarios - from small edge deployments to exabyte-scale migrations. This guide helps you choose the right service based on data volume, location, connectivity, and timing requirements.

---

## ğŸš€ Quick Service Selection Table

| Service                 | Data Capacity           | Best For                                                          | Connectivity Required |
| ----------------------- | ----------------------- | ----------------------------------------------------------------- | -------------------- |
| **AWS Snowcone**        | 8 TB (HDD) / 14 TB (SSD)| Edge computing in tight/mobile spaces (drones, vehicles, IoT)     | Optional (offline)   |
| **AWS Snowball Edge**   | 80 TB / 210 TB         | Medium migrations, edge computing with local processing           | Optional (offline)   |
| **AWS Snowmobile**      | Up to 100 PB per truck | Massive data center migrations (exabyte scale)                   | No (physical truck)  |
| **AWS DataSync**        | No limit                | Continuous/scheduled online transfers between locations           | Required (network)   |
| **AWS Transfer Family** | No limit                | Application-level FTP/SFTP transfers to S3/EFS                   | Required (network)   |
| **AWS Storage Gateway** | No limit                | Hybrid cloud storage extending on-premises to AWS                 | Required (network)   |

---

## ğŸŒ³ Data Transfer Decision Tree

```
Do you need to transfer data to AWS?
â”‚
â”œâ”€â”€> No â†’ âŒ No transfer needed
â”‚
â””â”€â”€> Yes
     â”‚
     â”œâ”€â”€ What's your data volume?
     â”‚   â”‚
     â”‚   â”œâ”€â”€ < 10 TB â†’ Continue to connectivity check â†“
     â”‚   â”œâ”€â”€ 10 TB - 100 TB â†’ Consider Snowball Edge or DataSync â†“
     â”‚   â”œâ”€â”€ 100 TB - 10 PB â†’ Definitely Snowball Edge (multiple) â†“
     â”‚   â””â”€â”€ > 10 PB â†’ âœ… Use Snowmobile
     â”‚
     â”œâ”€â”€ Do you have reliable high-speed internet?
     â”‚   â”‚
     â”‚   â”œâ”€â”€ Yes (>1 Gbps stable) â†’ Continue to transfer type â†“
     â”‚   â””â”€â”€ No/Limited â†’ Use physical devices (Snowball family) â†“
     â”‚
     â”œâ”€â”€ What type of transfer do you need?
     â”‚   â”‚
     â”‚   â”œâ”€â”€ One-time migration â†’ Physical devices or DataSync â†“
     â”‚   â”œâ”€â”€ Ongoing sync â†’ âœ… DataSync (scheduled)
     â”‚   â”œâ”€â”€ Application integration â†’ âœ… Transfer Family (FTP/SFTP)
     â”‚   â””â”€â”€ Hybrid storage â†’ âœ… Storage Gateway
     â”‚
     â”œâ”€â”€ Do you need edge computing capabilities?
     â”‚   â”‚
     â”‚   â”œâ”€â”€ Yes â†’ Choose Snowball Edge or Snowcone â†“
     â”‚   â””â”€â”€ No â†’ Continue to location analysis â†“
     â”‚
     â”œâ”€â”€ Where is your deployment location?
     â”‚   â”‚
     â”‚   â”œâ”€â”€ Space-constrained (vehicles, ships, remote) â†’ âœ… Snowcone
     â”‚   â”œâ”€â”€ Standard data center/office â†’ âœ… Snowball Edge
     â”‚   â””â”€â”€ Massive data center â†’ âœ… Snowmobile
     â”‚
     â””â”€â”€ Do you need specific protocols?
         â”‚
         â”œâ”€â”€ NFS file access â†’ Snowball Edge with NFS
         â”œâ”€â”€ FTP/SFTP endpoints â†’ âœ… Transfer Family
         â”œâ”€â”€ iSCSI/NFS gateway â†’ âœ… Storage Gateway
         â””â”€â”€ Standard S3 API â†’ Any Snowball device or DataSync
```

---

## ğŸ“‹ Service Deep Dive

### â„ï¸ AWS Snowcone
*Ultra-portable edge computing device*

**Physical Specifications:**
- **Weight:** 4.5 lbs (2.1 kg)
- **Size:** 9" x 6" x 3" (227mm x 148.6mm x 82.65mm)
- **Power:** 45W (can run on battery)
- **Environment:** Rugged, military-grade design

**Key Features:**
- âœ… 8 TB HDD or 14 TB SSD storage
- âœ… 4 GB memory, 2 vCPUs
- âœ… Runs EC2 instances and Lambda functions
- âœ… Wireless capability (WiFi)
- âœ… Multiple connectivity options

**Ideal Use Cases:**
```
ğŸš Drone Operations:
- Collect sensor data during flights
- Process imagery at the edge
- Sync to AWS when connected

ğŸš¢ Maritime Operations:
- Ship-to-shore data collection
- Offline processing of maritime data
- Sync during port visits

ğŸ¥ Healthcare (Mobile Units):
- Medical imaging in remote locations
- Patient data collection
- HIPAA-compliant edge processing

ğŸ¬ Content Creation:
- On-location video processing
- Real-time editing workflows
- Upload to S3 when connected
```

**Configuration Example:**
```bash
# Configure Snowcone for edge processing
aws configure set region us-west-2
aws snowball create-job \
    --job-type EXPORT \
    --address-id ADID1234 \
    --shipping-option NEXT_DAY \
    --snowball-capacity-preference T8
```

### ğŸ”ï¸ AWS Snowball Edge
*Robust edge computing and data transfer device*

**Device Options:**

**Snowball Edge Storage Optimized:**
- **Storage:** 210 TB (NVMe SSD)
- **Compute:** 52 vCPUs, 208 GB memory
- **Network:** 100 Gbps
- **Best for:** Large data migrations with some processing

**Snowball Edge Compute Optimized:**
- **Storage:** 80 TB (NVMe SSD) + optional GPU
- **Compute:** 104 vCPUs, 416 GB memory  
- **Network:** 100 Gbps + optional 10 Gbps
- **Best for:** ML inference, video analysis, industrial IoT

**Key Features:**
- âœ… NFS v3 file interface
- âœ… S3-compatible API
- âœ… Lambda functions at the edge
- âœ… EC2 instances (AMI support)
- âœ… AES-256 encryption with AWS KMS

**NFS Configuration Deep Dive:**

**What is NFS on Snowball Edge?**
- **NFS (Network File System)** allows you to mount the Snowball Edge as a network drive
- **Protocol:** NFSv3 with AES-256 encryption
- **Integration:** Works with existing backup and file management tools
- **Security:** All data encrypted, integrated with AWS KMS for key management

**NFS Setup Steps:**
```bash
# 1. Configure the Snowball Edge
snowballEdge configure-service --service-id nfs --service-configuration file://nfs-config.json

# 2. Start NFS service
snowballEdge start-service --service-id nfs

# 3. Mount on client (Linux)
sudo mkdir /mnt/snowball-nfs
sudo mount -t nfs 192.168.1.100:/buckets/my-bucket /mnt/snowball-nfs

# 4. Copy files directly
cp -r /data/* /mnt/snowball-nfs/
```

**Enterprise Migration Scenario:**
```
Company: Media Production House
Data: 500 TB of video files (on-premises NAS)
Challenge: Limited internet bandwidth (10 Mbps upload)

Solution with Snowball Edge:
1. Deploy Snowball Edge Storage Optimized (210 TB)
2. Enable NFS service
3. Mount existing NAS backup scripts to Snowball
4. Copy 210 TB â†’ Ship device â†’ Repeat for remaining data
5. Total time: 2 weeks vs 4+ months over internet
```

### ğŸš› AWS Snowmobile
*Exabyte-scale data transfer truck*

**Specifications:**
- **Capacity:** 100 PB per truck
- **Security:** 24/7 security personnel, GPS tracking
- **Environment:** Climate-controlled, shock-resistant
- **Timeline:** Weeks to months depending on data volume

**When to Use Snowmobile:**
```
âœ… Data volume > 10 PB
âœ… Entire data center migrations
âœ… Legacy system consolidation
âœ… Media archive migrations
âœ… Scientific data migrations

âŒ Don't use for:
- Small datasets (< 1 PB)
- Distributed locations
- Time-sensitive migrations (< 1 month)
- Locations without truck access
```

**Process Flow:**
```
1. Assessment & Planning (2-4 weeks)
   â”œâ”€ Site survey and planning
   â”œâ”€ Security clearance
   â””â”€ Network preparation

2. Snowmobile Deployment (1 week)
   â”œâ”€ Truck arrives at your location
   â”œâ”€ Network connection setup
   â””â”€ Security measures activation

3. Data Transfer (Weeks to months)
   â”œâ”€ Parallel data streams
   â”œâ”€ Continuous monitoring
   â””â”€ Progress reporting

4. Transport to AWS (1 week)
   â”œâ”€ Secure transport
   â”œâ”€ GPS tracking
   â””â”€ 24/7 monitoring

5. Data Ingestion (Weeks)
   â”œâ”€ Import to S3
   â”œâ”€ Data validation
   â””â”€ Customer notification
```

### ğŸ”„ AWS DataSync
*Online data transfer service*

**Key Features:**
- âœ… Up to 10 Gbps transfer speeds
- âœ… Built-in data validation
- âœ… Incremental transfers
- âœ… Bandwidth throttling
- âœ… Detailed transfer logs

**Supported Endpoints:**
```
Sources:
â”œâ”€ On-premises NFS/SMB shares
â”œâ”€ Amazon S3 buckets  
â”œâ”€ Amazon EFS file systems
â”œâ”€ Amazon FSx file systems
â””â”€ Google Cloud Storage

Destinations:
â”œâ”€ Amazon S3 (all storage classes)
â”œâ”€ Amazon EFS
â”œâ”€ Amazon FSx for Windows File Server
â”œâ”€ Amazon FSx for Lustre
â””â”€ Amazon FSx for NetApp ONTAP
```

**Transfer Scenarios:**

**Scenario 1: Hybrid File Sync**
```python
# Create DataSync task for daily backup
import boto3

datasync = boto3.client('datasync')

# Create task
response = datasync.create_task(
    SourceLocationArn='arn:aws:datasync:us-east-1:123456789012:location/loc-source',
    DestinationLocationArn='arn:aws:datasync:us-east-1:123456789012:location/loc-dest',
    Options={
        'VerifyMode': 'POINT_IN_TIME_CONSISTENT',
        'OverwriteMode': 'ALWAYS',
        'PreserveDeletedFiles': 'REMOVE',
        'BytesPerSecond': 104857600  # 100 Mbps limit
    },
    Schedule={
        'ScheduleExpression': 'cron(0 2 * * ? *)'  # Daily at 2 AM
    }
)
```

**Scenario 2: One-time Migration**
```bash
# Install DataSync agent on-premises
wget https://s3.amazonaws.com/datasync-downloads/DataSyncAgent.ova

# Create locations
aws datasync create-location-nfs \
    --server-hostname 192.168.1.100 \
    --subdirectory /shared/data \
    --on-prem-config AgentArns=arn:aws:datasync:us-east-1:123456789012:agent/agent-id

aws datasync create-location-s3 \
    --s3-bucket-arn arn:aws:s3:::my-migration-bucket \
    --s3-config BucketAccessRoleArn=arn:aws:iam::123456789012:role/DataSyncS3Role
```

### ğŸ“¡ AWS Transfer Family
*Managed FTP/SFTP/FTPS service*

**Supported Protocols:**
- **SFTP:** SSH File Transfer Protocol (most secure)
- **FTPS:** FTP over SSL/TLS
- **FTP:** File Transfer Protocol (legacy support)
- **AS2:** Applicability Statement 2 (B2B messaging)

**Key Features:**
- âœ… Fully managed (no server maintenance)
- âœ… Auto-scaling
- âœ… Integration with S3 and EFS
- âœ… Custom identity providers (LDAP, Active Directory)
- âœ… VPC endpoint support

**Authentication Methods:**

**Service-Managed Users:**
```bash
# Create SFTP server
aws transfer create-server \
    --protocols SFTP \
    --identity-provider-type SERVICE_MANAGED \
    --endpoint-type PUBLIC

# Add user
aws transfer create-user \
    --server-id s-1234567890abcdef0 \
    --user-name john.doe \
    --home-directory /my-bucket/john-folder \
    --role arn:aws:iam::123456789012:role/TransferRole \
    --ssh-public-key-body "ssh-rsa AAAAB3NzaC1yc2E..."
```

**Custom Identity Provider (LDAP):**
```python
# Lambda function for custom authentication
import json
import boto3

def lambda_handler(event, context):
    username = event['username']
    password = event['password']
    
    # Authenticate against LDAP
    if authenticate_ldap(username, password):
        return {
            'Role': 'arn:aws:iam::123456789012:role/TransferRole',
            'HomeDirectory': f'/my-bucket/users/{username}',
            'Policy': json.dumps({
                'Version': '2012-10-17',
                'Statement': [{
                    'Effect': 'Allow',
                    'Action': ['s3:GetObject', 's3:PutObject'],
                    'Resource': f'arn:aws:s3:::my-bucket/users/{username}/*'
                }]
            })
        }
    else:
        return {'Role': ''}  # Authentication failed
```

**B2B Integration Example:**
```
Trading Partner Setup:
â”œâ”€ Create dedicated SFTP server
â”œâ”€ Configure custom domain (ftp.company.com)
â”œâ”€ Set up partner-specific users and permissions
â”œâ”€ Enable CloudWatch logging for compliance
â””â”€ Implement automated file processing workflows
```

### ğŸŒ‰ AWS Storage Gateway
*Hybrid cloud storage gateway*

**Gateway Types:**

**File Gateway (NFS/SMB):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   On-Premises   â”‚    â”‚  File Gateway   â”‚    â”‚      AWS S3     â”‚
â”‚   Applications  â”‚â—„â”€â”€â–ºâ”‚   (VM/HW)       â”‚â—„â”€â”€â–ºâ”‚   Storage       â”‚
â”‚   (NFS/SMB)     â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Volume Gateway - Stored Volumes:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Applications  â”‚    â”‚ Volume Gateway  â”‚    â”‚      AWS S3     â”‚
â”‚   (iSCSI)       â”‚â—„â”€â”€â–ºâ”‚ Primary: Local  â”‚â—„â”€â”€â–ºâ”‚   Async Backup  â”‚
â”‚                 â”‚    â”‚ Backup: S3      â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Volume Gateway - Cached Volumes:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Applications  â”‚    â”‚ Volume Gateway  â”‚    â”‚      AWS S3     â”‚
â”‚   (iSCSI)       â”‚â—„â”€â”€â–ºâ”‚ Cache: Local    â”‚â—„â”€â”€â–ºâ”‚ Primary Storage â”‚
â”‚                 â”‚    â”‚ Primary: S3     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tape Gateway (VTL):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backup Software â”‚    â”‚  Tape Gateway   â”‚    â”‚ S3 / Glacier /  â”‚
â”‚ (Veeam, NetBackup)â—„â”€â”€â–ºâ”‚     (VTL)       â”‚â—„â”€â”€â–ºâ”‚ Glacier Deep    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   Archive       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Migration Architecture Patterns

### Pattern 1: Phased Data Center Migration
```
Phase 1: Assessment & Planning
â”œâ”€ Data discovery and classification
â”œâ”€ Network bandwidth analysis
â”œâ”€ Application dependency mapping
â””â”€ Migration timeline creation

Phase 2: Pilot Migration (Snowball Edge)
â”œâ”€ Select low-risk datasets (10-50 TB)
â”œâ”€ Test data validation processes
â”œâ”€ Verify application connectivity
â””â”€ Refine migration procedures

Phase 3: Bulk Migration (Multiple Snowballs/Snowmobile)
â”œâ”€ Large datasets (>100 TB)
â”œâ”€ Parallel data streams
â”œâ”€ Continuous monitoring
â””â”€ Regular progress reporting

Phase 4: Incremental Sync (DataSync)
â”œâ”€ Final delta sync
â”œâ”€ Application cutover
â”œâ”€ Post-migration validation
â””â”€ Decommission on-premises storage
```

### Pattern 2: Hybrid Cloud Storage Integration
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    On-Premises                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚    Apps     â”‚  â”‚   Storage   â”‚  â”‚   Backup    â”‚     â”‚
â”‚  â”‚             â”‚  â”‚   Gateway   â”‚  â”‚   Software  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ File Gateway    â”‚   â”‚    â”‚ Tape Gateway    â”‚
    â”‚ (NFS/SMB)       â”‚   â”‚    â”‚ (VTL)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚          â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS Cloud                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     S3      â”‚  â”‚   Glacier   â”‚  â”‚ Glacier DA  â”‚   â”‚
â”‚  â”‚   Standard  â”‚  â”‚   Flexible  â”‚  â”‚             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° Cost Analysis & Optimization

### Transfer Cost Comparison

**10 TB Dataset Transfer:**

| Method | Time | Direct Cost | Opportunity Cost | Total |
|--------|------|-------------|------------------|-------|
| **Internet (100 Mbps)** | 9 days | $0 | High (9 days downtime) | High |
| **Internet (1 Gbps)** | 22 hours | $0 | Medium (1 day) | Medium |
| **Snowball Edge** | 7-10 days | $300 + shipping | Low (parallel work) | Low |
| **DataSync** | 22 hours | $0.0125/GB = $125 | Medium | Medium |

**100 TB Dataset Transfer:**

| Method | Time | Direct Cost | Opportunity Cost | Total |
|--------|------|-------------|------------------|-------|
| **Internet (1 Gbps)** | 9 days | $0 | Very High | Very High |
| **Multiple Snowballs** | 2 weeks | $1,500 + shipping | Low | Low |
| **Snowmobile** | 4-6 weeks | $5,000/month | Very Low | Very Low |

### Snowball Edge Pricing Breakdown
```
Device Fees (per job):
â”œâ”€ Snowball Edge Storage Optimized: $300
â”œâ”€ Snowball Edge Compute Optimized: $400  
â”œâ”€ Additional days (after 10 free): $15/day
â””â”€ Shipping: $50-200 (depending on location)

Data Transfer:
â”œâ”€ Import to S3: Free
â”œâ”€ Export from S3: Standard rates apply
â””â”€ Cross-region transfer: Standard rates
```

### DataSync Pricing Optimization
```bash
# Configure bandwidth throttling to avoid ISP overages
aws datasync update-task \
    --task-arn arn:aws:datasync:region:account:task/task-id \
    --options BytesPerSecond=52428800  # 50 MB/s (400 Mbps)

# Schedule transfers during off-peak hours
aws datasync put-task-schedule \
    --task-arn arn:aws:datasync:region:account:task/task-id \
    --schedule-expression "cron(0 2 * * ? *)"  # 2 AM daily
```

---

## ğŸ”’ Security Best Practices

### Data Encryption Standards

**Snowball Family:**
- âœ… AES-256 encryption (FIPS 140-2 Level 2)
- âœ… Encrypted key management with AWS KMS
- âœ… Secure key erasure after import
- âœ… Tamper-evident enclosures

**DataSync:**
- âœ… TLS 1.2 encryption in transit
- âœ… VPC endpoint support (private connectivity)
- âœ… IAM integration for access control
- âœ… CloudTrail logging for audit

**Transfer Family:**
- âœ… SFTP with SSH key authentication
- âœ… FTPS with SSL/TLS certificates
- âœ… VPC endpoint for internal connectivity
- âœ… Custom identity providers (LDAP/AD)

### Network Security Configuration

**VPC Endpoint Setup for DataSync:**
```bash
# Create VPC endpoint for private DataSync access
aws ec2 create-vpc-endpoint \
    --vpc-id vpc-12345678 \
    --service-name com.amazonaws.region.datasync \
    --vpc-endpoint-type Interface \
    --subnet-ids subnet-12345678 subnet-87654321 \
    --security-group-ids sg-12345678 \
    --policy-document file://datasync-endpoint-policy.json
```

**Security Group Rules for Transfer Family:**
```json
{
    "SecurityGroupRules": [
        {
            "IpPermissions": [
                {
                    "IpProtocol": "tcp",
                    "FromPort": 22,
                    "ToPort": 22,
                    "IpRanges": [
                        {"CidrIp": "10.0.0.0/8", "Description": "Internal network SFTP"}
                    ]
                }
            ]
        }
    ]
}
```

---

## ğŸ“Š Monitoring & Troubleshooting

### CloudWatch Metrics

**DataSync Metrics:**
```bash
# Monitor transfer progress
aws cloudwatch get-metric-statistics \
    --namespace AWS/DataSync \
    --metric-name BytesTransferred \
    --dimensions Name=TaskId,Value=task-0123456789abcdef0 \
    --start-time 2023-10-01T00:00:00Z \
    --end-time 2023-10-07T23:59:59Z \
    --period 3600 \
    --statistics Sum
```

**Transfer Family Metrics:**
```python
import boto3
cloudwatch = boto3.client('cloudwatch')

# Create custom dashboard
cloudwatch.put_dashboard(
    DashboardName='TransferFamily-Monitoring',
    DashboardBody=json.dumps({
        "widgets": [
            {
                "type": "metric",
                "properties": {
                    "metrics": [
                        ["AWS/Transfer", "FilesIn", "ServerId", "s-1234567890abcdef0"],
                        [".", "FilesOut", ".", "."],
                        [".", "BytesIn", ".", "."],
                        [".", "BytesOut", ".", "."]
                    ],
                    "period": 300,
                    "stat": "Sum",
                    "region": "us-east-1",
                    "title": "Transfer Activity"
                }
            }
        ]
    })
)
```

### Common Troubleshooting Issues

**Snowball Edge Connectivity:**
```bash
# Check network configuration
snowballEdge describe-device
snowballEdge list-access-keys
snowballEdge associate-s3-access-key --access-key-id AKIAIOSFODNN7EXAMPLE

# Test NFS connectivity
showmount -e 192.168.1.100
mount -v -t nfs 192.168.1.100:/buckets/my-bucket /mnt/test
```

**DataSync Performance Issues:**
```
Common causes:
â”œâ”€ Network bandwidth limitations
â”œâ”€ Source storage performance bottlenecks  
â”œâ”€ Large number of small files
â”œâ”€ Network latency issues
â””â”€ Insufficient DataSync agent resources

Solutions:
â”œâ”€ Increase agent instance size
â”œâ”€ Use multiple parallel tasks
â”œâ”€ Optimize source storage performance
â”œâ”€ Implement bandwidth throttling
â””â”€ Archive small files before transfer
```

---

## ğŸ¯ Best Practices Summary

### Pre-Migration Planning
- [ ] Conduct thorough data assessment and classification
- [ ] Test network bandwidth and performance
- [ ] Plan for application dependencies and downtime
- [ ] Establish data validation procedures
- [ ] Create rollback plans for critical systems

### Security & Compliance
- [ ] Implement proper encryption for data at rest and in transit
- [ ] Use IAM roles with least privilege access
- [ ] Enable audit logging (CloudTrail, VPC Flow Logs)
- [ ] Validate compliance requirements (HIPAA, PCI, etc.)
- [ ] Test security controls before full migration

### Performance Optimization
- [ ] Choose appropriate transfer methods based on data volume
- [ ] Use parallel transfers when possible
- [ ] Optimize file formats and compression
- [ ] Monitor and tune network performance
- [ ] Implement proper error handling and retry logic

### Cost Management
- [ ] Compare total cost of ownership (TCO) for different methods
- [ ] Factor in opportunity costs and business impact
- [ ] Use Reserved Instances for predictable workloads
- [ ] Implement lifecycle policies for long-term storage
- [ ] Regular review and optimization of transfer patterns

---

*Last Updated: October 2025 | AWS SAA-C03 Study Guide*